{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# create an instance of the logger\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Change current directory to parent directory\n",
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              DateTime    Time_fault Fault  Time_scada  Error  \\\n",
      "0  2014-05-14 14:39:44  1.400096e+09    GF         NaN    NaN   \n",
      "1  2014-05-14 14:50:24  1.400097e+09    GF         NaN    NaN   \n",
      "2  2014-05-14 14:58:56  1.400098e+09    GF         NaN    NaN   \n",
      "3  2014-05-14 15:09:36  1.400098e+09    GF         NaN    NaN   \n",
      "4  2014-05-14 15:20:16  1.400099e+09    GF         NaN    NaN   \n",
      "\n",
      "   WEC: ava. windspeed  WEC: max. windspeed  WEC: min. windspeed  \\\n",
      "0                  NaN                  NaN                  NaN   \n",
      "1                  NaN                  NaN                  NaN   \n",
      "2                  NaN                  NaN                  NaN   \n",
      "3                  NaN                  NaN                  NaN   \n",
      "4                  NaN                  NaN                  NaN   \n",
      "\n",
      "   WEC: ava. Rotation  WEC: max. Rotation  ...  Inverter averages  \\\n",
      "0                 NaN                 NaN  ...                NaN   \n",
      "1                 NaN                 NaN  ...                NaN   \n",
      "2                 NaN                 NaN  ...                NaN   \n",
      "3                 NaN                 NaN  ...                NaN   \n",
      "4                 NaN                 NaN  ...                NaN   \n",
      "\n",
      "   Inverter std dev  Main Status  Sub Status  Full Status  Status Text   T  \\\n",
      "0               NaN          NaN         NaN          NaN          NaN NaN   \n",
      "1               NaN          NaN         NaN          NaN          NaN NaN   \n",
      "2               NaN          NaN         NaN          NaN          NaN NaN   \n",
      "3               NaN          NaN         NaN          NaN          NaN NaN   \n",
      "4               NaN          NaN         NaN          NaN          NaN NaN   \n",
      "\n",
      "   Service  FaultMsg  Value0  \n",
      "0      NaN       NaN     NaN  \n",
      "1      NaN       NaN     NaN  \n",
      "2      NaN       NaN     NaN  \n",
      "3      NaN       NaN     NaN  \n",
      "4      NaN       NaN     NaN  \n",
      "\n",
      "[5 rows x 76 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f1/tcfth2f16mv8s95myjjfx84h0000gn/T/ipykernel_13178/1649482415.py:7: DtypeWarning: Columns (2,70,71,73,74) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  merged_data = pd.read_csv(RAW_PATH_MERGED_DATA)\n"
     ]
    }
   ],
   "source": [
    "# Define global variables\n",
    "RAW_PATH_MERGED_DATA = 'data/processed/merged.csv'\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(RAW_PATH_MERGED_DATA):\n",
    "    # Load the file\n",
    "    merged_data = pd.read_csv(RAW_PATH_MERGED_DATA)\n",
    "    print(merged_data.head())\n",
    "else:\n",
    "    print(\"File not found:\", RAW_PATH_MERGED_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Seasonality (High or Low) as Feature for the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based Market Data Season Anaylsis, using Average and Max Settlement Point Price For Each Month In 2014\n",
    "\n",
    "### We determined\n",
    "\n",
    "#### Months of High Seasons as: **['Feb', 'Mar', 'Apr', 'May', 'Jun','Aug']**\n",
    "\n",
    "#### Months of High Seasons as: **['Jan', 'Jul', 'Sep', 'Oct', 'Nov','Dec']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             DateTime Month Season\n",
      "0 2014-05-14 14:39:44   May   High\n",
      "1 2014-05-14 14:50:24   May   High\n",
      "2 2014-05-14 14:58:56   May   High\n",
      "3 2014-05-14 15:09:36   May   High\n",
      "4 2014-05-14 15:20:16   May   High\n"
     ]
    }
   ],
   "source": [
    "# Define the mapping for high and low seasons\n",
    "SEASON_MAPPING = {\n",
    "    'Jan': 'Low',\n",
    "    'Feb': 'High',\n",
    "    'Mar': 'High',\n",
    "    'Apr': 'High',\n",
    "    'May': 'High',\n",
    "    'Jun': 'High',\n",
    "    'Jul': 'Low',\n",
    "    'Aug': 'High',\n",
    "    'Sep': 'Low',\n",
    "    'Oct': 'Low',\n",
    "    'Nov': 'Low',\n",
    "    'Dec': 'Low'\n",
    "}\n",
    "\n",
    "# Convert the 'DateTime' column to datetime if not already\n",
    "if 'DateTime' in merged_data.columns:\n",
    "    merged_data['DateTime'] = pd.to_datetime(merged_data['DateTime'])\n",
    "else:\n",
    "    logger.error(\"DateTime column is missing from the dataset.\")\n",
    "\n",
    "# Extract the month from the 'DateTime' column and map it to the season\n",
    "merged_data['Month'] = merged_data['DateTime'].dt.strftime('%b')  # Extract month abbreviation\n",
    "merged_data['Season'] = merged_data['Month'].map(SEASON_MAPPING)  # Map month to season\n",
    "\n",
    "# Display the updated dataset with the new 'Season' column\n",
    "print(merged_data[['DateTime', 'Month', 'Season']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze season-wise statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset with 'Season' column saved to data/processed/merged_with_season.csv\n",
      "  Season WEC: ava. Power         WEC: Production minutes\n",
      "                    mean     max                     sum\n",
      "0   High      840.817974  3070.0                621965.0\n",
      "1    Low     1030.455417  3071.0                791445.0\n"
     ]
    }
   ],
   "source": [
    "# Save the updated dataset if needed\n",
    "UPDATED_PATH = 'data/processed/merged_with_season.csv'\n",
    "merged_data.to_csv(UPDATED_PATH, index=False)\n",
    "print(f\"Updated dataset with 'Season' column saved to {UPDATED_PATH}\")\n",
    "\n",
    "# Optional: Analyze season-wise statistics\n",
    "season_stats = merged_data.groupby('Season').agg({\n",
    "    'WEC: ava. Power': ['mean', 'max'],  # Example columns for analysis\n",
    "    'WEC: Production minutes': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Display the season-wise stats\n",
    "print(season_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated dataset if needed\n",
    "# UPDATED_PATH = 'data/processed/merged_with_season.csv'\n",
    "# merged_data.to_csv(UPDATED_PATH, index=False)\n",
    "# print(f\"Updated dataset with 'Season' column saved to {UPDATED_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "turbine_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
